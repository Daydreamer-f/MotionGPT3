NAME: Webui_MGPT3 # Experiment name
DEBUG: False # Debug mode
ACCELERATOR: 'gpu' # Devices optioncal: “cpu”, “gpu”, “tpu”, “ipu”, “hpu”, “mps, “auto”
DEVICE: [0] # Index of gpus eg. [0] or [0,1,2,3]

# Training configuration
TRAIN:
  #---------------------------------
  STAGE: lm_instruct
  NUM_WORKERS: 32 # Number of workers
  BATCH_SIZE: 16 # Size of batches
  START_EPOCH: 0 # Start epochMMOTIONENCODER
  END_EPOCH: 99999 # End epoch
  ABLATION:
    pkeep: 0.5
  OPTIM:
    TYPE: AdamW # Optimizer type
    LR: 2e-4 # Learning rate
    WEIGHT_DECAY: 0.0
    LR_SCHEDULER: [100, 200, 300, 400]
    GAMMA: 0.8

# Evaluating Configuration
EVAL:
  BATCH_SIZE: 32 # Evaluating Batch size
  SPLIT: test

# Test Configuration
TEST:
  CHECKPOINTS: checkpoints/motiongpt3.ckpt
  SPLIT: test
  BATCH_SIZE: 32 # training Batch size
  MEAN: False
  NUM_SAMPLES: 1
  FACT: 1

# Datasets Configuration
DATASET:
  target: motGPT.data.webui.HumanML3DDataModule

METRIC:
  TYPE: ['TM2TMetrics']
# Losses Configuration
LOSS:
  # TYPE: t2mgpt # Losses type
  LAMBDA_FEATURE: 1.0
  LAMBDA_VELOCITY: 0.5
  LAMBDA_COMMIT: 0.02
  LAMBDA_CLS: 1.0
  LAMBDA_DIFF: 0.5
  LAMBDA_M2T2M: 1.0
  LAMBDA_T2M2T: 10.0
  ABLATION:
    RECONS_LOSS: 'l1_smooth'

lm_ablation:
  # lm
  motion_holder_repeat: 4
  holder_num_in_input: 4
  motion_holder_seq_mode: 'withse' # 'alone', 'withse'
  with_hid_norm: False
  with_vae_latent_norm: True
  # diffloss
  multi_hidden: True
  guidance_scale: 7.5
  model_guidance_scale: 7.5
  diffusion_batch_mul: 4
  guidance_uncondp: 0.1
  predict_epsilon: True
  fake_latent_mode: 'learnable_zero'  # 'all_zero', 'learnable_rand', 'learnable_zero'
  # mot arch
  mot_factor: 1.0
  attention_mode: 'all'

# Model Configuration
model:
  target: motGPT.models.motgpt_webui.MotGPT
  params:
    condition: 'text'
    task: 't2m'
    lm: ${lm.mot_vae_gpt2}
    motion_vae: ${vae.mldvae}
    mot_factor: 1.0
    attention_mode: 'all'
    guidance_scale: ${lm_ablation.model_guidance_scale}
    with_vae_latent_norm: ${lm_ablation.with_vae_latent_norm}
  diff_loss: ${lm.diffloss}

# Logger configuration
LOGGER:
  LOG_EVERY_STEPS: 5
  VAL_EVERY_STEPS: 10
  TENSORBOARD: True
  wandb:
    params:
      project: null
